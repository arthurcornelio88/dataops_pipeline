# ‚öôÔ∏è `dataops_pipeline` ‚Äî Airflow Setup on GCP VM

This repository runs the production orchestration for fraud detection using Apache Airflow.
The setup is designed to run manually on a clean **Debian-based VM on Google Cloud Platform**.

---

## ‚úÖ 1. System setup (one-time, on a fresh VM)

Run the following commands after VM creation:

```bash
sudo apt-get update -y
sudo apt-get install -y git curl python3-pip
```

---

## üì¶ 2. Clone the project

```bash
git clone https://gitlab.com/automatic_fraud_detection_b3/dataops_pipeline.git
cd dataops_pipeline
```

---

## üöÄ 3. Run the Airflow environment setup

This script installs:

* `uv` (dependency manager)
* Apache Airflow `2.8.4`
* Google provider `10.1.1`
* and sets up the local environment

```bash
export ENV="PROD"
export REFERENCE_DATA_PATH="fraudTest.csv" # Change it according to your configuration
export GCP_PROJECT="jedha2024" # Change it according to your configuration

chmod +x setup_vm_airflow.sh
./setup_vm_airflow.sh
```

---

## üåÄ 4. Launch Airflow

```bash

souce .env
source .env.airflow
source .venv/bin/activate

# Start the webserver and scheduler
airflow webserver --port 8080 &
airflow scheduler &
```

Airflow UI: `http://<YOUR_VM_PUBLIC_IP>:8080`

> To kill process and restart Airflow : `pkill airflow & pkill guvicorn`, then, relaunch.
---

## üåê 5. Get your IP & open port 8080 in GCP

* From the VM:

  ```bash
  curl ifconfig.me
  ```

* In the GCP Console:
  Go to **VPC > Firewall rules**, and create a rule:

| Field            | Value                                 |
| ---------------- | ------------------------------------- |
| Name             | `allow-airflow-8080`                  |
| Targets          | All instances in the network          |
| Protocols/Ports  | TCP: `8080`                           |
| Source IP Ranges | `0.0.0.0/0` *(or restrict as needed)* |

---

## üìÇ 6. DAGs to enable in the UI

Once Airflow is running, enable the following DAGs:

* `fetch_api_data` ‚Äî fetches real-time payments every minute
* `predict_payments` ‚Äî runs fraud prediction batch jobs
* `monitor_fraud` ‚Äî monitors predictions and triggers alerts

---

## ‚ö†Ô∏è Requirements

Make sure the following components are configured:

* ‚úÖ GCP **storage bucket**
* ‚úÖ GCP **BigQuery datasets** (`raw_api_data`, `predictions`)
* ‚úÖ GCP **service account key** (`GOOGLE_APPLICATION_CREDENTIALS`)
* ‚úÖ **Discord webhook** for alert notifications

---