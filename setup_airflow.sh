#!/bin/bash

set -e

echo "📦 Setting up Airflow local environment..."

# Step 1: Create folders
mkdir -p airflow_home dags logs

# Step 2: Create .env.airflow
cat > .env.airflow <<EOF
# Auto-generated by setup_airflow.sh

export ENV=$ENV
export GOOGLE_CLOUD_PROJECT=$GOOGLE_CLOUD_PROJECT
export REFERENCE_DATA_PATH=$REFERENCE_DATA_PATH
export AIRFLOW_HOME=\$(pwd)/airflow_home
export AIRFLOW__CORE__DAGS_FOLDER=\$(pwd)/dags
export AIRFLOW__LOGGING__BASE_LOG_FOLDER=\$(pwd)/logs
export AIRFLOW__CORE__LOAD_EXAMPLES=False
export AIRFLOW__CORE__EXECUTOR=SequentialExecutor
EOF

echo "✅ .env.airflow created"

# Step 3: Load environment
source .env.airflow

echo "DEBUG : Environment variables loaded: ${ENV}, ${GOOGLE_CLOUD_PROJECT}, ${REFERENCE_DATA_PATH}, ${AIRFLOW_HOME}"

# Step 4: Clean previous metadata and cache
rm -rf "\$AIRFLOW_HOME"/* dags/__pycache__ logs/*
echo "🧹 Cleaned \$AIRFLOW_HOME"

# Step 5: Reset and migrate Airflow DB
airflow db reset -y
airflow db migrate
echo "✅ Airflow DB reset and migrated"

# Step 6: Create admin user
echo "👤 Creating admin user..."
airflow users create \
  --username admin \
  --firstname Arthur \
  --lastname Cornelio \
  --role Admin \
  --email admin@fraud.dev \
  --password admin
echo "👤 Admin user created: admin / admin"

# Step 7: Sync permissions (critical fix)
airflow sync-perm
echo "🔄 Permissions synced with roles"

# Step 8: Create .airflowignore
echo -e "__pycache__/\nlogs/" > dags/.airflowignore
echo "📁 .airflowignore created in dags/"

# Final instructions
echo ""
echo "🎉 All set! Use the following commands to launch Airflow:"
echo "source .venv/bin/activate"
echo "source .env.airflow"
echo "airflow scheduler &"
echo "airflow webserver --port 8080"
echo "🔗 Access Airflow UI at: http://localhost:8080"
